# 도서 대출 시스템에 ElasticSearch 도입으로 검색 품질 높이기

## 주제 선정 이유
> 선정 이유는 도서 대출 시스템의 **검색 기능**을 개발하던 중, 대규모 데이터에서 **검색 속도와 품질** 문제를 해결하기 위한 방법을 찾기 위해서 입니다.


## 1. 시작 — 주제 소개와 목차

안녕하세요. **도서 대출 시스템에 ElasticSearch 도입으로 검색 품질 높이기**라는 주제로 정리합니다. 글의 큰 구성은 발표와 같습니다.
1) 기존 검색 시스템의 문제점, 2) ElasticSearch(ES) 소개, 3) ES 도입 과정과 효과, 4) 도입 시 주의할 점, 5) 마무리.  
   이 순서를 **슬라이드 흐름**에 맞춰 그대로 따라갑니다.

---

## 2. 기존 검색 시스템의 문제점

### 2.1 우리는 보통 어떻게 검색 쿼리를 작성하나?
RDB에서 가장 먼저 떠올리는 건 `LIKE` 연산자입니다. 간단히 예를 들면:

```sql
SELECT [필드명]
FROM [테이블명]
WHERE [필드명] LIKE '%특정 문자열%';
```


간편하고, 소규모 데이터에선 그럭저럭 동작합니다. 하지만 이 방식엔 분명한 한계가 있습니다.

### 2.2 실제 수치로 본 한계 — 100만, 900만, 1억
제가 만든 **도서 대출 시스템**에서 실제로 조회해 보니,
- **100만 건**에서 `자바` 검색: **약 5.3초**
- **900만 건**에서 동일 검색: **약 10초**
- **1억 건**이라면? 더 오래 걸릴 뿐 아니라 **정상 동작을 장담하기 어렵다**는 생각이 들었습니다.

### 2.3 왜 이렇게 오래 걸릴까? — FULL TABLE SCAN
`'%키워드%'` 패턴은 **시작점을 특정할 수 없어** 인덱스를 타지 못합니다. 결국 **FULL TABLE SCAN**이 발생해 테이블을 **처음부터 끝까지** 다 훑게 됩니다. 데이터가 커질수록 시간이 **선형적으로** 늘어납니다.

### 2.4 “인덱스를 쓰면 되지 않나?”에 대한 답 — B-Tree 제약
B-Tree 인덱스는 **정렬된 키의 시작점**을 알아야 탐색이 빠릅니다. 그래서
- `LIKE 'keyword%'`는 **가능**하지만
- `LIKE '%keyword%'`는 **시작점 불명확**으로 **불가능**합니다.

### A-1. LIKE 검색의 한계가 드러나는 예
```sql
-- 인덱스 사용 불가: 시작점이 없어 FULL TABLE SCAN
SELECT * FROM books WHERE title LIKE '%자바%';

-- 인덱스 사용 가능하지만 사용성 저하: 접두(prefix) 일치만 허용
SELECT * FROM books WHERE title LIKE '자바%';
```

이건 단지 성능 이슈를 넘어 **사용성**을 해칩니다. 예를 들어 사용자가 `자바`라고 검색했을 때 **“모던 자바 인 액션”**처럼 **중간**에 `자바`가 있는 제목은 잘 잡히지 않습니다. 사용자 입장에선 “원하는 결과가 위에 잘 안 뜨는” 상황이 계속 생깁니다.

결국 인덱스를 못 타면 **디스크 I/O가 증가**하고, 그 결과 **응답 지연**이 발생하며, 심하면 **DB 전체 성능을 끌어내립니다.**

### 2.5 Full-Text Index로의 개선과 그 한계
MySQL **FULL-TEXT INDEX**를 적용하면 **속도**는 꽤 나아집니다. 하지만 한국어에서 **토큰 최소 길이 기본값이 3**이라 **“자바(2글자)”**가 토큰으로 잡히지 않는 문제가 생깁니다. 최소 길이를 2로 낮추면 **인덱스가 급팽창**하고, 여전히 `'%…%'` 같은 **부분 검색은 불가**합니다.  
즉, **속도는 조금 개선**되지만 **검색 UX 품질(부분 검색/자동완성/오타/연관도)** 관점에선 **한계**가 남습니다.

> 여기까지가 “왜 기존 방식으로는 한계에 부딪히는가”에 대한 정리입니다.

---

## 3. ElasticSearch 소개

### 3.1 ES는 무엇인가?
**ElasticSearch(ES)** 는 **루씬(Lucene)** 기반의 오픈소스 검색엔진입니다. 문서를 **JSON** 형태로 **색인**해 저장하고, 그 색인을 이용해 **아주 빠르게 검색**합니다.  
핵심 특징은 **준 실시간 검색**, **분산 아키텍처**, **다양한 검색 기능**, **유연한 스키마(동적 매핑)**, **REST API** 지원 등입니다.

### 3.2 왜 빠른가 — 역인덱스(inverted index)
ES는 텍스트를 **토큰** 단위로 분석하고, **토큰 → 문서 목록**을 미리 만들어 둡니다. 책 뒤쪽의 “**키워드 색인**”과 같은 발상입니다. 덕분에 검색 시 토큰이 맞으면 **바로 해당 문서 후보군**으로 점프할 수 있어, 체감 속도가 완전히 달라집니다.

### 3.3 분산 아키텍처 — 수평 확장과 고가용성
ES는 **여러 노드**가 하나의 **클러스터**처럼 동작합니다. 부족하면 **노드를 추가**해 **수평 확장**할 수 있고, 특정 노드에 문제가 생겨도 **다른 노드가 역할을 대신**해 **고가용성**을 달성합니다.

### 3.4 REST API — 언어 불문 쉬운 연동
GET/POST/PUT/DELETE 같은 **표준 HTTP** 인터페이스로 다룰 수 있어, 언어에 상관없이 쉽게 붙일 수 있습니다.

### 3.5 다양한 검색 기능 — 한국어 형태소, 자동완성, 오타 교정
- **한국어 형태소 분석기(Nori)** 로 공백 분할로는 놓치는 의미 단위를 잘라낼 수 있습니다.
- **자동완성**과 **오타 교정** 같은 **검색 UX 기능**을 자연스럽게 붙일 수 있습니다.
- **동적 매핑(Dynamic Mapping)** 으로 필드 타입을 자동 추론해 매핑을 생성할 수 있지만, 이건 어디까지나 **시작점**일 뿐입니다(뒤에서 주의점으로 다시 다룹니다).

형태소 분석 확인 예시는 아래처럼 했습니다.

```json
GET _analyze
{
  "tokenizer": "nori_tokenizer",
  "text": ["혼자 공부하는 운영체제와 컴퓨터 구조"]
}
```

---

## 4. ES 도입 — 실제 시스템에서 어떻게 달라졌나

### 4.1 100만/900만 건에서의 체감 성능
ES로 바꾸고 나서 속도는 이렇게 바뀌었습니다.
- **100만 건**: **약 5.3초 → 약 22ms**
- **900만 건**: **약 10초 → 약 23ms**

데이터가 9배로 커져도 **체감 속도**는 거의 그대로입니다. **역인덱스**와 **분산 구조**의 힘입니다.

### 4.2 정렬과 연관도 — “가장 관련 있는 결과”를 위로
ES는 기본적으로 **BM25** 같은 **연관도 알고리즘**을 이용해 결과를 정렬합니다. 단순 포함 여부가 아니라, **현재 검색 의도와의 관련도**가 높은 문서가 상단에 뜹니다.

### 4.3 오타 허용 — “공보하는”을 쳐도 “공부하는”을 찾아간다
검색창에 `혼자 공보하는 자바`라고 잘못 쳐도, ES는 **fuzziness(오타 허용)** 을 통해 사용자의 의도를 따라갑니다. “원하는 책”에 자연스럽게 도달합니다.

### 4.4 자동완성 — 타이핑하는 즉시 길을 열어준다
일부 글자만 입력해도 **유효한 후보**를 바로 보여줍니다. 다음과 같은 식으로 구현했습니다.

```json
POST books/_search
{
  "suggest": {
    "title_suggest": {
      "prefix": "자바",
      "completion": {
        "field": "title_suggest",
        "size": 5
      }
    }
  }
}
```

---

## 5. ES 도입 시 주의할 점

### 5.1 왜 “준” 실시간인가 — 색인과 검색의 간격
ES는 색인 직후 곧바로 검색되는 **완전 실시간**이 아닙니다. 내부적으로 **commit/flush/refresh** 과정이 있고, 보통 **약 1초 정도 지연**이 있습니다. 실시간 트랜잭션 시스템처럼 동작한다고 가정하면 안 됩니다.

또한 ES는 **트랜잭션 롤백을 지원하지 않습니다**. 작업 단위를 어떻게 쪼개고, 실패 시 어떻게 **idempotent**하게 복구할지 등 **운영 설계**가 필요합니다.

부분 업데이트는 내부적으로 **기존 문서 삭제 + 새 문서 생성**으로 동작합니다. 작은 수정도 결국 재색인 비용이 들기 때문에, 인덱스/파이프라인 설계를 신중히 해야 합니다.

그리고 **매핑은 한번 정하면 변경이 어렵습니다.** 자동완성 같은 스키마 변경이 생기면, 보통 **새 인덱스를 생성**하고 **재색인**해야 합니다.

### 5.2 동적 매핑만 믿지 말 것 + 샤드 설계
동적 매핑은 시작을 빠르게 해주지만, **값의 범위/정밀도**를 고려해야 하는 필드(예: 금액, 점수 등)는 **정적 매핑**으로 타입을 **명시**하는 편이 안전합니다. 예를 들어 `float`로 자동 추론됐는데 더 큰 값이 들어올 수 있다면 처음부터 `double`로 고정해야 합니다.

또 하나, **샤드 개수**는 성능·메모리·확장성·장애 복구 속도에 모두 영향을 줍니다. 기본값 1로도 개발 환경에서는 문제없을 수 있지만, **운영에서는 데이터량과 트래픽을 보고** 샤드/레플리카를 **초기부터 설계**하는 게 좋습니다.

---

## 6. 마무리 — 왜 ES였나

정리하자면 이렇습니다.

- **RDB**는 데이터를 **정확하고 일관되게 저장**하기 위한 기술입니다.
- **ElasticSearch**는 **대용량 텍스트를 빠르고 유연하게 검색**하기 위한 기술입니다.

저는 저장과 검색을 분리했습니다. 그 결과, **속도 문제**와 **검색 UX 품질**을 동시에 끌어올릴 수 있었습니다. 특히 **부분 검색/오타 허용/자동완성/연관도 정렬** 같은 요소는 사용자 경험을 완전히 다르게 만듭니다. **도서 대출 시스템**처럼 검색이 핵심인 서비스라면, ES 도입을 **첫 번째 선택지**로 충분히 고려할 만합니다.


## 참고:
- inflearn - elasticsearch essential
- 엘라스틱서치 바이블
