# 도서 대출 시스템에 ElasticSearch 도입으로 검색 품질 높이기

> 선정 이유: 도서 대출 시스템의 **검색 기능**을 개발하던 중, 대규모 데이터에서 **검색 속도**와 **검색 품질**이 급격히 떨어지는 문제를 해결하기 위해 다양한 방법을 고민했고, ElasticSearch 도입으로 개선한 경험을 정리했습니다.

## 목차
- [주제 선정 이유](#주제-선정-이유)
- [기존 검색 시스템의 문제점](#기존-검색-시스템의-문제점)
- [ElasticSearch 소개](#elasticsearch-소개)
- [ES 도입 — 실제 시스템에서 어떻게 달라졌나](#es-도입--실제-시스템에서-어떻게-달라졌나)
- [ES 도입 시 주의할 점](#es-도입-시-주의할-점)
- [마무리 — 왜 ES였나](#마무리--왜-es였나)
- [참고](#참고)

---

## 주제 선정 이유
도서 대출 시스템의 검색 기능을 구현하면서 가장 먼저 부딪힌 건 **속도**였습니다.  
작은 데이터셋에서는 빠르게 동작하지만, 데이터가 커지자 검색 한 번에 수초씩 대기해야 했고,  
부분 검색·자동완성·오타 허용 같은 UX 요구사항도 충족되지 않았습니다.  
이 문제를 해결하고자 RDB의 한계를 정리하고, ElasticSearch(ES)를 적용하게 되었습니다.

---

## 기존 검색 시스템의 문제점

우리가 보통 검색 쿼리를 작성할 때 가장 먼저 떠올리는 건 `LIKE` 연산자입니다.

```sql
SELECT [필드명]
FROM [테이블명]
WHERE [필드명] LIKE '%특정 문자열%';
```

간단하고 구현이 쉬우나, 데이터가 많아지면 성능이 급격히 나빠집니다.

- **100만 건**: 약 5.3초
- **900만 건**: 약 10초
- **1억 건**이라면? 더 오래 걸릴 뿐 아니라 정상 작동 보장도 어렵습니다.

`'%키워드%'`는 인덱스를 탈 수 없어 테이블 전체를 훑는 **FULL TABLE SCAN**이 발생합니다.  
데이터가 커질수록 시간이 선형적으로 증가합니다.

```sql
-- 인덱스 사용 불가: 시작점이 없어 FULL TABLE SCAN
SELECT * FROM books WHERE title LIKE '%자바%';

-- 인덱스 사용 가능하지만 접두(prefix) 일치만 허용
SELECT * FROM books WHERE title LIKE '자바%';
```

접두 일치는 가능하지만, 사용자가 원하는 중간 단어 검색(부분 검색)이 불가능하여 검색 UX가 떨어집니다.

MySQL **FULL-TEXT INDEX**를 적용하면 속도는 개선되지만,
- 토큰 최소 길이(기본 3)로 인해 “자바(2글자)”가 누락
- 길이를 2로 낮추면 인덱스가 급격히 커짐
- 여전히 `%...%` 부분 검색 불가

즉, **속도는 조금 개선**되지만 **검색 UX 품질(부분 검색/자동완성/오타/연관도)** 관점에선 여전히 한계가 남습니다.

---

## ElasticSearch 소개

**ElasticSearch(ES)** 는 **루씬(Lucene)** 기반의 오픈소스 검색 엔진입니다.  
문서를 **JSON**으로 색인하고, **역인덱스**를 활용해 빠르게 검색합니다.  
핵심 특징은 **준실시간 검색**, **분산 아키텍처**, **REST API 지원**, **동적 매핑**, **다양한 검색 기능**입니다.

ES는 텍스트를 토큰 단위로 분석하고 **토큰 → 문서 목록**을 미리 만들어 두어 키워드로 바로 문서를 찾습니다.  
책 뒤쪽 색인과 같은 원리로 O(1)에 가까운 검색 속도를 체감할 수 있습니다.

ElasticSearch는 **분산 아키텍처**를 통해 노드를 추가하여 수평 확장이 가능하고, 특정 노드 장애 시 다른 노드가 역할을 대신해 **고가용성**을 확보합니다.  
또한 **REST API** 기반으로 GET/POST/PUT/DELETE 같은 표준 HTTP 인터페이스를 지원해 언어에 구애받지 않고 쉽게 연동할 수 있습니다.

추가로 **한국어 형태소 분석기(Nori)** 를 이용하면 공백 단위 분리로는 놓치는 의미 단위를 잘게 나눌 수 있어 더 나은 검색 품질을 제공합니다.

```json
GET _analyze
{
  "tokenizer": "nori_tokenizer",
  "text": ["혼자 공부하는 운영체제와 컴퓨터 구조"]
}
```

자동완성, 오타 허용, 연관도 정렬(BM25) 등 다양한 검색 UX 기능도 제공됩니다.

---

## ES 도입 — 실제 시스템에서 어떻게 달라졌나

도입 후 속도는 이렇게 개선되었습니다.

- **100만 건**: 5.3초 → 22ms
- **900만 건**: 10초 → 23ms  
  데이터 9배 증가에도 체감 속도는 동일합니다.

검색 품질도 크게 향상되었습니다.

- **연관도 정렬**로 더 관련도 높은 결과 우선 노출
- **오타 허용**으로 “공보하는”도 “공부하는”으로 매칭
- **자동완성**으로 일부 글자만 입력해도 검색 후보 제공

```json
POST books/_search
{
  "suggest": {
    "title_suggest": {
      "prefix": "자바",
      "completion": {
        "field": "title_suggest",
        "size": 5
      }
    }
  }
}
```

---

## ES 도입 시 주의할 점

ElasticSearch는 강력하지만, 도입할 때 몇 가지 주의할 점이 있습니다.

먼저 **완전 실시간이 아님**을 알아야 합니다. ES는 색인 직후 곧바로 검색되는 것이 아니라, 내부적으로 commit, flush, refresh 과정을 거쳐 약 1초 후에야 검색할 수 있습니다. 실시간 시스템에서 이 지연을 고려하지 않으면 데이터가 누락된 것처럼 보일 수 있습니다.

또한 **트랜잭션 롤백이 지원되지 않습니다.** 한 번 색인된 데이터는 취소할 수 없고, 별도의 삭제 요청을 해야 합니다. 대량 색인 시에는 같은 데이터가 중복으로 들어가지 않도록 idempotent 설계를 하는 것이 필수입니다.

**부분 업데이트가 불가능**하다는 점도 유의해야 합니다. ES에서의 업데이트는 사실상 기존 문서를 삭제하고 새로운 문서를 색인하는 방식으로 동작합니다. 작은 필드 하나만 변경해도 전체 문서를 다시 색인해야 하므로 설계 단계에서 변경이 잦은 데이터와 그렇지 않은 데이터를 분리해두는 것이 좋습니다.

**매핑 변경도 불가능**합니다. 필드 타입이나 분석기를 바꾸려면 새 인덱스를 만들고 데이터를 재색인해야 합니다. 저도 자동완성 필드를 추가하려다 결국 인덱스를 새로 만들고 전체 데이터를 다시 밀어 넣었습니다. 따라서 처음 설계 단계에서 매핑을 신중히 정의해야 합니다.

그리고 **동적 매핑만 믿어서는 안 됩니다.** 모든 필드를 자동으로 색인하게 두면 불필요한 리소스 낭비가 발생하고, 숫자 필드가 잘못된 타입으로 추론될 수 있습니다. 예를 들어 가격이 커질 가능성이 있다면 처음부터 double 타입으로 정의하는 것이 안전합니다.

마지막으로 **샤드와 레플리카 설계**도 중요합니다. 샤드 수는 검색 성능, 메모리 사용량, 노드 확장성, 장애 복구 속도에 영향을 줍니다. 기본값 1로는 개발 단계에서는 괜찮지만, 운영 환경에서는 데이터 크기와 트래픽 패턴을 고려해 적절히 조정해야 합니다.

---

## 마무리 — 왜 ES였나

정리하자면 RDB는 데이터를 **정확하고 일관되게 저장**하기 위한 기술이고,  
ElasticSearch는 대규모 텍스트를 **빠르고 유연하게 검색**하기 위한 기술입니다.  
저는 두 기술의 역할을 분리해 속도 문제와 UX 품질을 동시에 해결할 수 있었습니다.  
특히 부분 검색, 오타 허용, 자동완성, 연관도 정렬 같은 기능은 사용자 경험을 완전히 바꿔주었고,  
검색이 중요한 시스템이라면 ES 도입은 충분히 고려할 만한 선택이라고 생각합니다.

---

## 참고
- [Inflearn - ElasticSearch Essential](https://www.inflearn.com/course/elasticsearch-essential)
- [엘라스틱서치 바이블](https://product.kyobobook.co.kr/detail/S000001804054)
